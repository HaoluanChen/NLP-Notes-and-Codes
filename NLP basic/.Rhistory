coord_flip() +
theme_minimal()+
labs(title ="Waterloo")
uoftpairs <- uoft %>%
select( "created_at", "text") %>%
unnest_tokens(word, text, token = "words") %>%
anti_join(stop_words) %>%
filter(!(word == "t.co" | word == "https" | word == "amp"))
ut_word_pairs <- uoftpairs %>%
pairwise_count(word, created_at, sort = TRUE, upper = FALSE)
ut_word_pairs
uwpairs <- Uw %>%
select( "created_at", "text") %>%
unnest_tokens(word, text, token = "words") %>%
anti_join(stop_words) %>%
filter(!(word == "t.co" | word == "https"| word == "amp"))
uw_word_pairs <- uwpairs %>%
pairwise_count(word, created_at, sort = TRUE, upper = FALSE)
uw_word_pairs
set.seed(1234)
ut_word_pairs %>%
filter(n >= 10) %>%
graph_from_data_frame() %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "cyan4") +
geom_node_point(size = 3) +
geom_node_text(aes(label = name), repel = TRUE,
point.padding = unit(0.2, "lines")) +
theme_void()
uw_word_pairs %>%
filter(n >= 10) %>%
graph_from_data_frame() %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "cyan4") +
geom_node_point(size = 3) +
geom_node_text(aes(label = name), repel = TRUE,
point.padding = unit(0.2, "lines")) +
theme_void()
ut_tf_idf <- uoft %>%
select( "created_at", "text") %>%
unnest_tokens(word, text, token = "words") %>%
anti_join(stop_words) %>%
filter(!(word == "t.co" | word == "https" | word == "amp")) %>%
count(word, sort = TRUE) %>%
mutate(id = "ut")
ut_tf_idf
uw_tf_idf <- Uw %>%
select( "created_at", "text") %>%
unnest_tokens(word, text, token = "words") %>%
anti_join(stop_words) %>%
filter(!(word == "t.co" | word == "https" | word == "amp")) %>%
count(word, sort = TRUE) %>%
mutate(id = "uw")
uw_tf_idf
data_tf_idf <- rbind(ut_tf_idf, uw_tf_idf)
data_tf_idf<- data_tf_idf %>%
ungroup() %>%
bind_tf_idf(word, id, n) %>%
arrange(desc(tf_idf))
data_tf_idf
data_tf_idf %>%
mutate(word = factor(word, levels = rev(unique(word)))) %>%
group_by(id) %>%
top_n(15) %>%
ungroup() %>%
ggplot(aes(word, tf_idf, fill = id)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~id, ncol = 2, scales = "free") +
coord_flip()+
theme_minimal()
tidy_data  <- rbind(ut_tf_idf, uw_tf_idf)
tidy_data
twitter_dtm <- tidy_data %>%
cast_dfm(id, word, n)
twitter_dtm
twitter_lda <- LDA(twitter_dtm, k = 10, control = list(seed = 1234))
twitter_lda
tidy_lda <- tidy(twitter_lda)
tidy_lda
top_terms <- tidy_lda %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
top_terms
top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
group_by(topic, term) %>%
arrange(desc(beta)) %>%
ungroup() %>%
ggplot(aes(term, beta, fill = as.factor(topic))) +
geom_col(show.legend = FALSE) +
coord_flip() +
scale_x_reordered() +
labs(title = "Top 10 terms in each LDA topic",
x = NULL, y = expression(beta)) +
facet_wrap(~ topic, ncol = 4, scales = "free")
twitter_lda <- LDA(twitter_dtm, k = 15, control = list(seed = 1234))
tidy_lda <- tidy(twitter_lda)
top_terms <- tidy_lda %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
group_by(topic, term) %>%
arrange(desc(beta)) %>%
ungroup() %>%
ggplot(aes(term, beta, fill = as.factor(topic))) +
geom_col(show.legend = FALSE) +
coord_flip() +
scale_x_reordered() +
labs(title = "Top 10 terms in each LDA topic",
x = NULL, y = expression(beta)) +
facet_wrap(~ topic, ncol = 4, scales = "free")
twitter_lda <- LDA(twitter_dtm, k = 6, control = list(seed = 1234))
tidy_lda <- tidy(twitter_lda)
top_terms <- tidy_lda %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
group_by(topic, term) %>%
arrange(desc(beta)) %>%
ungroup() %>%
ggplot(aes(term, beta, fill = as.factor(topic))) +
geom_col(show.legend = FALSE) +
coord_flip() +
scale_x_reordered() +
labs(title = "Top 10 terms in each LDA topic",
x = NULL, y = expression(beta)) +
facet_wrap(~ topic, ncol = 4, scales = "free")
tidy_tweets_ut2 <- uoft %>%
select( "created_at", "text") %>%
unnest_tokens(word, text, token = "words") %>%
anti_join(stop_words)%>%
filter(!(word == "t.co" | word == "https" | word == "amp"))
tidy_tweets_ut2<- tidy_tweets_ut2 %>% count(word,created_at, sort = TRUE)
tidy_tweets_uw2 <- Uw %>%
select( "created_at", "text") %>%
unnest_tokens(word, text, token = "words") %>%
anti_join(stop_words)%>%
filter(!(word == "t.co" | word == "https" | word == "amp"))
tidy_tweets_uw2<- tidy_tweets_uw2 %>% count(word, created_at, sort = TRUE)
tidy_tweets_ut2
tidy_tweets_uw2
tidy_tweets <- rbind(tidy_tweets_ut2,tidy_tweets_uw2 )
tidy_tweets
twitter_dtm <- tidy_tweets %>%
cast_dfm(created_at, word, n)
twitter_dtm
twitter_lda <- LDA(twitter_dtm, k = 6, control = list(seed = 1234))
tidy_lda <- tidy(twitter_lda)
top_terms <- tidy_lda %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
group_by(topic, term) %>%
arrange(desc(beta)) %>%
ungroup() %>%
ggplot(aes(term, beta, fill = as.factor(topic))) +
geom_col(show.legend = FALSE) +
coord_flip() +
scale_x_reordered() +
labs(title = "Top 10 terms in each LDA topic",
x = NULL, y = expression(beta)) +
facet_wrap(~ topic, ncol = 4, scales = "free")
frequency <- frequency %>%
inner_join(get_sentiments("afinn"), by = "word")
frequency_uw <- frequency_uw %>%
inner_join(get_sentiments("afinn"), by = "word")
frequency %>%
mutate(word = reorder(word, value)) %>%
filter(value >= 4|value < -2) %>%
ggplot(aes(word, value, fill = value > 0)) +
geom_col(show.legend = FALSE) +
coord_flip() +
ylab("Average sentiment value")
frequency_uw %>%
mutate(word = reorder(word, value)) %>%
filter(value >= 4|value < -2) %>%
ggplot(aes(word, value, fill = value > 0)) +
geom_col(show.legend = FALSE) +
coord_flip() +
ylab("Average sentiment value")
tidy_tweets_ut <- uoft %>%
select( "created_at", "text") %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
ut_bigram <- uoft %>%
select( "created_at", "text") %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
knitr::opts_chunk$set(echo = TRUE)
library(tm)
library(dplyr)
library(tidytext)
library(ggplot2)
library(ggthemes)
library(tidyr)
library(topicmodels)
library(rtweet)
library(wordcloud)
library(widyr)
library(igraph)
library(ggraph)
# get data set
uoft <- get_favorites(user = "UofT")
uoft
Uw <- get_favorites(user = "UWaterloo")
Uw
tidy_tweets_ut <- uoft %>%
select( "created_at", "text") %>%
unnest_tokens(word, text, token = "words") %>%
anti_join(stop_words) %>%
count(word, sort = TRUE)
tidy_tweets_ut
tidy_tweets_ut %>% summarise(total = n()) # total words for ut
frequency<- tidy_tweets_ut %>%
mutate(freq = n/2972)
frequency<- frequency %>%
filter(!(word == "t.co" | word == "https"))
tidy_tweets_uw <- Uw %>%
select( "created_at", "text") %>%
unnest_tokens(word, text, token = "words") %>%
anti_join(stop_words) %>%
count(word, sort = TRUE)
tidy_tweets_uw %>% summarise(total = n())  # total words for uw
frequency_uw<- tidy_tweets_uw %>%
mutate(freq = n/3094)
frequency_uw <- frequency_uw %>%
filter(!(word == "t.co" | word == "https"))
frequency %>%
top_n(n) %>%
mutate(word = reorder(word, freq)) %>%
ggplot(aes(word, freq)) +
geom_col( fill = ("red"), colour = "black") +
coord_flip() +
theme_minimal()
frequency_uw %>%
top_n(n) %>%
mutate(word = reorder(word, freq)) %>%
ggplot(aes(word, freq)) +
geom_col( fill = ("#00abff"), colour = "black") +
coord_flip() +
theme_minimal()+
labs(title ="Waterloo")
uoftpairs <- uoft %>%
select( "created_at", "text") %>%
unnest_tokens(word, text, token = "words") %>%
anti_join(stop_words) %>%
filter(!(word == "t.co" | word == "https" | word == "amp"))
ut_word_pairs <- uoftpairs %>%
pairwise_count(word, created_at, sort = TRUE, upper = FALSE)
ut_word_pairs
uwpairs <- Uw %>%
select( "created_at", "text") %>%
unnest_tokens(word, text, token = "words") %>%
anti_join(stop_words) %>%
filter(!(word == "t.co" | word == "https"| word == "amp"))
uw_word_pairs <- uwpairs %>%
pairwise_count(word, created_at, sort = TRUE, upper = FALSE)
uw_word_pairs
set.seed(1234)
ut_word_pairs %>%
filter(n >= 10) %>%
graph_from_data_frame() %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "cyan4") +
geom_node_point(size = 3) +
geom_node_text(aes(label = name), repel = TRUE,
point.padding = unit(0.2, "lines")) +
theme_void()
uw_word_pairs %>%
filter(n >= 10) %>%
graph_from_data_frame() %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "cyan4") +
geom_node_point(size = 3) +
geom_node_text(aes(label = name), repel = TRUE,
point.padding = unit(0.2, "lines")) +
theme_void()
ut_tf_idf <- uoft %>%
select( "created_at", "text") %>%
unnest_tokens(word, text, token = "words") %>%
anti_join(stop_words) %>%
filter(!(word == "t.co" | word == "https" | word == "amp")) %>%
count(word, sort = TRUE) %>%
mutate(id = "ut")
ut_tf_idf
uw_tf_idf <- Uw %>%
select( "created_at", "text") %>%
unnest_tokens(word, text, token = "words") %>%
anti_join(stop_words) %>%
filter(!(word == "t.co" | word == "https" | word == "amp")) %>%
count(word, sort = TRUE) %>%
mutate(id = "uw")
uw_tf_idf
data_tf_idf <- rbind(ut_tf_idf, uw_tf_idf)
data_tf_idf<- data_tf_idf %>%
ungroup() %>%
bind_tf_idf(word, id, n) %>%
arrange(desc(tf_idf))
data_tf_idf
data_tf_idf %>%
mutate(word = factor(word, levels = rev(unique(word)))) %>%
group_by(id) %>%
top_n(15) %>%
ungroup() %>%
ggplot(aes(word, tf_idf, fill = id)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~id, ncol = 2, scales = "free") +
coord_flip()+
theme_minimal()
tidy_data  <- rbind(ut_tf_idf, uw_tf_idf)
tidy_data
twitter_dtm <- tidy_data %>%
cast_dfm(id, word, n)
twitter_dtm
twitter_lda <- LDA(twitter_dtm, k = 10, control = list(seed = 1234))
twitter_lda
tidy_lda <- tidy(twitter_lda)
tidy_lda
top_terms <- tidy_lda %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
top_terms
top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
group_by(topic, term) %>%
arrange(desc(beta)) %>%
ungroup() %>%
ggplot(aes(term, beta, fill = as.factor(topic))) +
geom_col(show.legend = FALSE) +
coord_flip() +
scale_x_reordered() +
labs(title = "Top 10 terms in each LDA topic",
x = NULL, y = expression(beta)) +
facet_wrap(~ topic, ncol = 4, scales = "free")
twitter_lda <- LDA(twitter_dtm, k = 15, control = list(seed = 1234))
tidy_lda <- tidy(twitter_lda)
top_terms <- tidy_lda %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
group_by(topic, term) %>%
arrange(desc(beta)) %>%
ungroup() %>%
ggplot(aes(term, beta, fill = as.factor(topic))) +
geom_col(show.legend = FALSE) +
coord_flip() +
scale_x_reordered() +
labs(title = "Top 10 terms in each LDA topic",
x = NULL, y = expression(beta)) +
facet_wrap(~ topic, ncol = 4, scales = "free")
twitter_lda <- LDA(twitter_dtm, k = 6, control = list(seed = 1234))
tidy_lda <- tidy(twitter_lda)
top_terms <- tidy_lda %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
group_by(topic, term) %>%
arrange(desc(beta)) %>%
ungroup() %>%
ggplot(aes(term, beta, fill = as.factor(topic))) +
geom_col(show.legend = FALSE) +
coord_flip() +
scale_x_reordered() +
labs(title = "Top 10 terms in each LDA topic",
x = NULL, y = expression(beta)) +
facet_wrap(~ topic, ncol = 4, scales = "free")
tidy_tweets_ut2 <- uoft %>%
select( "created_at", "text") %>%
unnest_tokens(word, text, token = "words") %>%
anti_join(stop_words)%>%
filter(!(word == "t.co" | word == "https" | word == "amp"))
tidy_tweets_ut2<- tidy_tweets_ut2 %>% count(word,created_at, sort = TRUE)
tidy_tweets_uw2 <- Uw %>%
select( "created_at", "text") %>%
unnest_tokens(word, text, token = "words") %>%
anti_join(stop_words)%>%
filter(!(word == "t.co" | word == "https" | word == "amp"))
tidy_tweets_uw2<- tidy_tweets_uw2 %>% count(word, created_at, sort = TRUE)
tidy_tweets_ut2
tidy_tweets_uw2
tidy_tweets <- rbind(tidy_tweets_ut2,tidy_tweets_uw2 )
tidy_tweets
twitter_dtm <- tidy_tweets %>%
cast_dfm(created_at, word, n)
twitter_dtm
twitter_lda <- LDA(twitter_dtm, k = 6, control = list(seed = 1234))
tidy_lda <- tidy(twitter_lda)
top_terms <- tidy_lda %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
group_by(topic, term) %>%
arrange(desc(beta)) %>%
ungroup() %>%
ggplot(aes(term, beta, fill = as.factor(topic))) +
geom_col(show.legend = FALSE) +
coord_flip() +
scale_x_reordered() +
labs(title = "Top 10 terms in each LDA topic",
x = NULL, y = expression(beta)) +
facet_wrap(~ topic, ncol = 4, scales = "free")
frequency <- frequency %>%
inner_join(get_sentiments("afinn"), by = "word")
frequency_uw <- frequency_uw %>%
inner_join(get_sentiments("afinn"), by = "word")
frequency %>%
mutate(word = reorder(word, value)) %>%
filter(value >= 4|value < -2) %>%
ggplot(aes(word, value, fill = value > 0)) +
geom_col(show.legend = FALSE) +
coord_flip() +
ylab("Average sentiment value")
frequency_uw %>%
mutate(word = reorder(word, value)) %>%
filter(value >= 4|value < -2) %>%
ggplot(aes(word, value, fill = value > 0)) +
geom_col(show.legend = FALSE) +
coord_flip() +
ylab("Average sentiment value")
ut_bigram <- uoft %>%
select( "created_at", "text") %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
ut_bigram
ut_bigram_count <- ut_bigram %>%
count(bigram, sort = TRUE)
ut_bigram_count
ut_bigram_count <- ut_bigram %>%
count(bigram, sort = TRUE) %>%
separate(bigram, c("word1", "word2"), sep = " ")
ut_bigram_count
ut_bigram %>%
filter(word1 %in% negate_words) %>%
count(word1, word2, wt = n, sort = TRUE) %>%
inner_join(get_sentiments("afinn"), by = c(word2 = "word")) %>%
mutate(contribution = value * n) %>%
group_by(word1) %>%
top_n(10, abs(contribution)) %>%
ungroup() %>%
mutate(word2 = reorder(paste(word2, word1, sep = "__"), contribution)) %>%
ggplot(aes(word2, contribution, fill = contribution > 0)) +
geom_col(show.legend = FALSE) +
facet_wrap(~ word1, scales = "free", nrow = 3) +
scale_x_discrete(labels = function(x) gsub("__.+$", "", x)) +
xlab("Words preceded by a negation") +
ylab("Sentiment value * # of occurrences") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
coord_flip()
ut_bigram_count <- ut_bigram %>%
count(bigram, sort = TRUE) %>%
separate(bigram, c("word1", "word2"), sep = " ")
ut_bigram_count
negate_words <- c("not", "without", "no", "can't", "don't", "won't")
ut_bigram %>%
filter(word1 %in% negate_words) %>%
count(word1, word2, wt = n, sort = TRUE) %>%
inner_join(get_sentiments("afinn"), by = c(word2 = "word")) %>%
mutate(contribution = value * n) %>%
group_by(word1) %>%
top_n(10, abs(contribution)) %>%
ungroup() %>%
mutate(word2 = reorder(paste(word2, word1, sep = "__"), contribution)) %>%
ggplot(aes(word2, contribution, fill = contribution > 0)) +
geom_col(show.legend = FALSE) +
facet_wrap(~ word1, scales = "free", nrow = 3) +
scale_x_discrete(labels = function(x) gsub("__.+$", "", x)) +
xlab("Words preceded by a negation") +
ylab("Sentiment value * # of occurrences") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
coord_flip()
ut_bigram %>%
filter(word1 %in% negate_words)
ut_bigram_count %>%
filter(word1 %in% negate_words)
ut_bigram_count %>%
filter(word1 %in% negate_words) %>%
count(word1, word2, wt = n, sort = TRUE) %>%
inner_join(get_sentiments("afinn"), by = c(word2 = "word")) %>%
mutate(contribution = value * n) %>%
group_by(word1) %>%
top_n(10, abs(contribution)) %>%
ungroup() %>%
mutate(word2 = reorder(paste(word2, word1, sep = "__"), contribution)) %>%
ggplot(aes(word2, contribution, fill = contribution > 0)) +
geom_col(show.legend = FALSE) +
facet_wrap(~ word1, scales = "free", nrow = 3) +
scale_x_discrete(labels = function(x) gsub("__.+$", "", x)) +
xlab("Words preceded by a negation") +
ylab("Sentiment value * # of occurrences") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
coord_flip()
