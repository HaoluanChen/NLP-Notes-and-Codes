mutate(sex = str_replace(sex ,"-", "NA"),
sex = str_replace(sex, "Unknown", "NA"))
data1 %>%
ggplot(aes(sex)) +
geom_bar()
data1 <- data1 %>%
mutate(sex = str_replace(sex ,"-", "NA"),
sex = str_replace(sex, "Unknown", "NA")
sex = str_replace_na())
data1 <- data1 %>%
mutate(sex = str_replace(sex ,"-", "NA"),
sex = str_replace(sex, "Unknown", "NA"),
sex = str_replace_na())
data1 <- data1 %>%
mutate(sex = str_replace(sex ,"-", "NA"),
sex = str_replace(sex, "Unknown", "NA"),
sex = str_replace_na(sex) )
data1 %>%
ggplot(aes(sex)) +
geom_bar()
dead %>%
ggplot(aes(sex)) +
geom_bar()
dead <- data1 %>%
filter(dead == TRUE)
dead %>%
ggplot(aes(sex)) +
geom_bar()
data1 %>% count(sex)
data1 %>%
ggplot(aes(sex)) +
geom_bar()
dead <- data1 %>%
filter(dead == TRUE) %>%
count(sex)
dead %>%
ggplot(aes(sex)) +
geom_bar()
dead <- data1 %>%
filter(dead == TRUE) %>%
count(sex)
dead %>%
ggplot(aes(sex)) +
geom_bar()
dead <- data1 %>%
filter(dead == TRUE) %>%
dead %>%
ggplot(aes(sex)) +
geom_bar()
dead <- data1 %>%
filter(dead == TRUE) %>%
dead %>%
ggplot(aes(sex)) +
geom_bar()
dead <- data1 %>%
filter(dead == TRUE)
dead %>%
ggplot(aes(sex)) +
geom_bar()
dead %>% count(sex)
data %>%
ggplot(aes(mass)) +
gemo_histogram()
data %>%
ggplot(aes(mass)) +
geom_histogram()
data %>%
ggplot(aes(mass)) +
geom_histogram()
data %>%
ggplot(aes(cl)) +
geom_histogram()
data %>%
ggplot(aes(pl)) +
geom_histogram()
data %>%
ggplot(aes(ch)) +
geom_histogram()
glimpse(data)
setwd("C:/Users/chl19/Desktop/STA497 Reading/NLP intermediate")
knitr::opts_chunk$set(echo = TRUE)
library(stringr)
library(hcandersenr)
library(tidyverse)
library(tidytext)
fir_tree <- hca_fairytales() %>%
filter(
book == "The fir tree",
language == "English"
)
knitr::opts_chunk$set(echo = TRUE)
library(stringr)
library(hcandersenr)
library(tidyverse)
library(tidytext)
fir_tree <- hca_fairytales() %>%
filter(
book == "The fir tree",
language == "English"
)
tidy_fir_tree <- fir_tree %>%
unnest_tokens(word, text)
tidy_fir_tree %>%
filter(!(word %in% stopwords(source = "snowball")))
knitr::opts_chunk$set(echo = TRUE)
library(stringr)
library(hcandersenr)
library(tidyverse)
library(tidytext)
library(stopwords)
length(stopwords(source = "smart"))
length(stopwords(source = "snowball"))
length(stopwords(source = "stopwords-iso"))
str_subset(stopwords(source = "smart"), "'")
fir_tree <- hca_fairytales() %>%
filter(
book == "The fir tree",
language == "English"
)
tidy_fir_tree <- fir_tree %>%
unnest_tokens(word, text)
tidy_fir_tree %>%
filter(!(word %in% stopwords(source = "snowball")))
tidy_fir_tree %>%
anti_join(get_stopwords(source = "snowball"))
fir_tree <- hca_fairytales() %>%
filter(
book == "The fir tree",
language == "English"
)
fir_tree <- hca_fairytales() %>%
filter(
book == "The fir tree",
language == "English"
)
library(SnowballC)
tidy_fir_tree %>%
mutate(stem = wordStem(word)) %>%
count(stem, sort = TRUE)
tidy_fir_tree <- fir_tree %>%
unnest_tokens(word, text) %>%
anti_join(get_stopwords())
tidy_fir_tree %>%
mutate(stem = wordStem(word)) %>%
count(stem, sort = TRUE)
library(hunspell)
tidy_fir_tree %>%
mutate(stem = hunspell_stem(word)) %>%
unnest(stem) %>%
count(stem, sort = TRUE)
hunspell_stem("discontented")
knitr::opts_chunk$set(echo = TRUE)
library(stringr)
library(hcandersenr)
library(tidyverse)
library(tidytext)
library(SnowballC)
tidy_fir_tree %>%
count(word, sort = TURE)
tidy_fir_tree %>%
count(word, sort = TRUE)
tidy_fir_tree %>%
count(case_name, word)
library(scotus)
hca_fairytales()
hca_fairytales()filter(language == "English")
hca_fairytales() %>% filter(language == "English")
hca_fairytales() %>% filter(language == "English") %>% count()
hca_fairytales() %>% filter(language == "English") %>% count(word)
hca_fairytales() %>% filter(language == "English") %>%
unnest_tokens(word, text)
hca_fairytales() %>% filter(language == "English") %>%
unnest_tokens(word, text) %>%
count(book, word)
hca_fairytales() %>% filter(language == "English") %>%
unnest_tokens(word, text) %>%
count(book, word) %>%
cast_dfm(book, word, n)
hca_fairytales() %>% filter(language == "English") %>%
unnest_tokens(word, text) %>%
count(book, word) %>%
anti_join(get_stopwords())
hca_fairytales() %>% filter(language == "English") %>%
unnest_tokens(word, text) %>%
count(book, word) %>%
anti_join(get_stopwords())
cast_dfm(book, word, n)
hca_fairytales() %>% filter(language == "English") %>%
unnest_tokens(word, text) %>%
count(book, word) %>%
anti_join(get_stopwords())
hca_fairytales() %>% filter(language == "English") %>%
unnest_tokens(word, text) %>%
count(book, word) %>%
anti_join(get_stopwords())
cast_dfm(book, word, n)
hca_fairytales() %>% filter(language == "English") %>%
unnest_tokens(word, text) %>%
count(book, word) %>%
anti_join(get_stopwords())
hca_fairytales() %>% filter(language == "English") %>%
unnest_tokens(word, text) %>%
count(book, word) %>%
anti_join(get_stopwords()) %>%
cast_dfm(book, word, n)
hca_fairytales() %>% filter(language == "English") %>%
unnest_tokens(word, text) %>%
count(book, word) %>%
anti_join(get_stopwords()) %>%
mutate(stem = wordStem(word)) %>%
count(book, stem) %>%
cast_dfm(book, stem, n)
tidy_fir_tree %>%
count(word, sort = TRUE) %>%
filter(str_detect(word, "^tree"))
fir_tree_counts <- fir_tree %>%
unnest_tokens(word, text, token = "regex", pattern = "\\s+|[[:punct:]]+") %>%
anti_join(get_stopwords()) %>%
mutate(stem = wordStem(word)) %>%
count(stem, sort = TRUE)
fir_tree_counts
fir_tree_counts <- fir_tree %>%
unnest_tokens(word, text, token = "regex", pattern = "\\s+|[[:punct:]]+") %>% # space or punctuation
anti_join(get_stopwords()) %>%
mutate(stem = wordStem(word)) %>%
count(stem, sort = TRUE)
fir_tree_counts
fir_tree_counts <- fir_tree %>%
unnest_tokens(word, text, token = "regex", pattern = "\\s+|[[:punct:]]+") %>% # space or punctuation
anti_join(get_stopwords()) %>%
mutate(stem = wordStem(word)) %>%
count(stem, sort = TRUE)
fir_tree_counts %>%
filter(str_detect(stem, "^tree"))
knitr::opts_chunk$set(echo = TRUE)
library(stringr)
library(hcandersenr)
library(tidyverse)
library(tidytext)
library(SnowballC)
fir_tree %>%
unnest_tokens(word, text)
fir_tree %>%
unnest_tokens(word, text) %>%
add_count(word)
?add_count
fir_tree %>%
unnest_tokens(word, text) %>%
add_count(word) %>%
filter(n>= 50)
fir_tree %>%
unnest_tokens(word, text) %>%
count(word) %>%
filter(n>= 50)
fir_tree %>%
unnest_tokens(word, text) %>%
count(word, book) %>%
filter(n>= 50)
fir_tree %>%
unnest_tokens(word, text) %>%
count(word, book) %>%
filter(n>= 50) %>%
select(-n)
nested_words <- fir_tree %>%
unnest_tokens(word, text) %>%
count(word, book) %>%
filter(n>= 50) %>%
select(-n) %>%
nest(words = c(word))
nested_words
nested_words <- hca_fairytales() %>%
filter(language == "English") %>%
unnest_tokens(word, text) %>%
count(word, book) %>%
filter(n>= 50) %>%
select(-n) %>%
nest(words = c(word))
nested_words
nested_words <- hca_fairytales() %>%
filter(language == "English") %>%
unnest_tokens(word, text) %>%
count(word, book) %>%
filter(n>= 50) %>%
select(-n) %>%
nested_words
nested_words <- hca_fairytales() %>%
filter(language == "English") %>%
unnest_tokens(word, text) %>%
count(word, book) %>%
filter(n>= 50) %>%
select(-n)
nested_words
nested_words <- hca_fairytales() %>%
filter(language == "English") %>%
unnest_tokens(word, text) %>%
count(word, book)
nested_words
nested_words <- hca_fairytales() %>%
filter(language == "English") %>%
unnest_tokens(word, text)
nested_words
nested_words <- hca_fairytales() %>%
filter(language == "English") %>%
unnest_tokens(word, text) %>%
add_count(word)
nested_words
nested_words <- hca_fairytales() %>%
filter(language == "English") %>%
unnest_tokens(word, text) %>%
add_count(word) %>%
filter(n>=50)
nested_words
nest(words = c(word))
nested_words <- hca_fairytales() %>%
filter(language == "English") %>%
unnest_tokens(word, text) %>%
add_count(word) %>%
filter(n>=50) %>%
nest(words = c(word))
nested_words
nested_words <- hca_fairytales() %>%
filter(language == "English") %>%
unnest_tokens(word, text) %>%
add_count(word) %>%
filter(n>=50) %>%
nest(words = c(word)) %>%
select(-n)
nested_words
library(widyr)
library(furrr)
plan(multiprocess) ## for parallel processing
tidy_pmi <- nested_words %>%
mutate(words = future_map(words, slide_windows, 4,
.progress = TRUE
)) %>%
unnest(words) %>%
unite(window_id, complaint_id, window_id) %>%
pairwise_pmi(word, window_id)
complaints <- read_csv("data/complaints.csv.gz")
complaints <- read_csv("complaints.csv")
tidy_complaints <- complaints %>%
select(complaint_id, consumer_complaint_narrative) %>%
unnest_tokens(word, consumer_complaint_narrative) %>%
add_count(word) %>%
filter(n >= 50) %>%
select(-n)
complaints <- read_csv("complaints.csv")
tidy_complaints <- complaints %>%
select(complaint_id, consumer_complaint_narrative) %>%
unnest_tokens(word, consumer_complaint_narrative) %>%
add_count(word) %>%
filter(n >= 50) %>%
select(-n)
View(complaints)
complaints <- read_csv("complaints.csv")
tidy_complaints <- complaints %>%
select(`Complaint ID`, consumer_complaint_narrative) %>%
unnest_tokens(word, consumer_complaint_narrative) %>%
add_count(word) %>%
filter(n >= 50) %>%
select(-n)
complaints <- read_csv("complaints.csv")
tidy_complaints <- complaints %>%
select(`Complaint ID`, consumer_complaint_narrative) %>%
unnest_tokens(word, consumer_complaint_narrative) %>%
add_count(word) %>%
filter(n >= 50) %>%
select(-n)
complaints <- read_csv("complaints.csv")
tidy_complaints <- complaints %>%
select(`Complaint ID`, `Consumer complaint narrative`) %>%
unnest_tokens(word, `Consumer complaint narrative`) %>%
add_count(word) %>%
filter(n >= 50) %>%
select(-n)
nested_words <- tidy_complaints %>%
nest(words = c(word))
nested_words
library(widyr)
library(furrr)
plan(multiprocess) ## for parallel processing
tidy_pmi <- nested_words %>%
mutate(words = future_map(words, slide_windows, 4,
.progress = TRUE
)) %>%
unnest(words) %>%
unite(window_id, complaint_id, window_id) %>%
pairwise_pmi(word, window_id)
library(widyr)
library(furrr)
plan(multiprocess) ## for parallel processing
tidy_pmi <- nested_words %>%
mutate(words = future_map(words, slide_windows, 4,
.progress = TRUE
)) %>%
unnest(words) %>%
unite(window_id, complaint_id, window_id) %>%
pairwise_pmi(word, window_id)
library(widyr)
library(furrr)
plan(multiprocess) ## for parallel processing
tidy_pmi <- nested_words %>%
mutate(words = future_map(words, slide_windows, 4,
.progress = TRUE
)) %>%
unnest(words) %>%
unite(window_id, complaint_id, window_id) %>%
pairwise_pmi(word, window_id)
library(textdata)
glove6b <- embedding_glove6b(dimensions = 100)
glove6b
library(textdata)
glove6b <- embedding_glove6b(dimensions = 50)
glove6b
tidy_glove <- glove6b %>%
pivot_longer(contains("d"),
names_to = "dimension"
) %>%
rename(item1 = token)
tidy_glove
tidy_glove %>%
nearest_neighbors("error")
nearest_neighbors <- function(df, token) {
df %>%
widely(
~ . %*% (.[token, ]),
sort = TRUE,
maximum_size = NULL
)(item1, dimension, value) %>%
select(-item2)
}
tidy_glove %>%
nearest_neighbors("error")
tidy_glove %>%
nearest_neighbors("month")
tidy_glove %>%
nearest_neighbors("NLP")
tidy_glove %>%
nearest_neighbors("NLP")
tidy_glove %>%
nearest_neighbors("statistics")
knitr::opts_chunk$set(echo = TRUE)
library(stringr)
library(hcandersenr)
library(tidyverse)
library(tidytext)
library(SnowballC)
library(widyr)
library(furrr)
plan(multiprocess) ## for parallel processing
tidy_pmi <- nested_words %>%
mutate(words = future_map(words, slide_windows, 4,
.progress = TRUE
)) %>%
unnest(words) %>%
unite(window_id, complaint_id, window_id) %>%
pairwise_pmi(word, window_id)
knitr::opts_chunk$set(echo = TRUE)
library(stringr)
library(hcandersenr)
library(tidyverse)
library(tidytext)
library(SnowballC)
nearest_neighbors <- function(df, token) {
df %>%
widely(
~ . %*% (.[token, ]),
sort = TRUE,
maximum_size = NULL
)(item1, dimension, value) %>%
select(-item2)
}
tidy_glove %>%
nearest_neighbors("error")
tidy_glove <- glove6b %>%
pivot_longer(contains("d"),
names_to = "dimension"
) %>%
rename(item1 = token)
tidy_glove
nearest_neighbors <- function(df, token) {
df %>%
widely(
~ . %*% (.[token, ]),
sort = TRUE,
maximum_size = NULL
)(item1, dimension, value) %>%
select(-item2)
}
tidy_glove %>%
nearest_neighbors("error")
library(widyr)
library(widyr)
nearest_neighbors <- function(df, token) {
df %>%
widely(
~ . %*% (.[token, ]),
sort = TRUE,
maximum_size = NULL
)(item1, dimension, value) %>%
select(-item2)
}
tidy_glove %>%
nearest_neighbors("error")
library(spacyr)
install.packages("spacyr")
library(spacyr)
spacy_initialize(entity = FALSE)
library(spacyr)
spacy_initialize(entity = FALSE)
library(spacyr)
spacy_initialize(entity = FALSE)
